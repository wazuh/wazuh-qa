from curses import meta
import json
import os
import re
import pytest
from wazuh_testing.tools import file
from wazuh_testing.tools import configuration
from subprocess import run

test_data_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'data')

test_cases_path = os.path.join(test_data_path, 'test_cases')
feed_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), '..', 'data')


# Configuration and cases data
test_invalid_feeds_path = os.path.join(test_cases_path, 'cases_invalid_feed.yaml')

test_input_empty_feed_path = os.path.join(feed_path, 'input_feed', 'invalid_feed', 'empty_feed.json')
test_input_txt_feed_path = os.path.join(feed_path, 'input_feed', 'invalid_feed', 'feed.txt')
test_input_invalid_json_feed_path = os.path.join(feed_path, 'input_feed', 'invalid_feed', 'invalid_feed_json.json')
test_input_invalid_xml_feed_path = os.path.join(feed_path, 'input_feed', 'invalid_feed', 'invalid_feed_xml.xml')



test_output_feed_path = os.path.join(feed_path, 'output_feed', 'cve5.json')

_, configuration_metadata, test_case_ids = configuration.get_test_cases_data(test_invalid_feeds_path)

# Set offline custom feeds configuration
to_modify = ['CUSTOM_EMPTY_FEED_JSON_PATH', 'CUSTOM_TXT_FEED_JSON_PATH', 'CUSTOM_INVALID_JSON_PATH',
             'CUSTOM_INVALID_XML_PATH']
new_values = [test_input_empty_feed_path, test_input_txt_feed_path, test_input_invalid_json_feed_path,
              test_input_invalid_xml_feed_path]

configuration_metadata = configuration.update_configuration_template(configuration_metadata, to_modify, new_values)

output_path = "/home/belen/Feed-output/build/"
parser_type_json = "JSON"


@pytest.mark.parametrize('metadata', configuration_metadata, ids=test_case_ids)
def test_format_cve5(metadata):

    print(test_output_feed_path)
    # Validate input file is a correct json
    #assert file.validate_json_file(test_input_txt_feed_path), "File is not JSON 'parseable'"

    # Execute migration tool
    os.chdir("/home/belen/Repositories/wazuh-content/build/third_party_migration/")
    lala = os.system(f"./content_migration -i {metadata['feed_path']} -t {metadata['format']} -o {output_path}")
    print(metadata['feed_path'])
    print(metadata['format'])


 
    # Validate output file is a correct json
    assert file.validate_json_file(test_output_feed_path), "File is not JSON 'parseable'"


    # Validate required keys
    #cve5_file= file.read_json_file(test_output_feed_path)

    # source = ["source"]
    # data = ["data"]
    # operation = ["data", 0, "operation"]
    # cve_id = ["data", 0, "cve_id"]
    # data_hash = ["data", 0, "data_hash"]
    # data_blob = ["data", 0, "data_blob"]
    # data_type = ["data", 0, "data_blob", "data", 0, "dataType"]
    # data_version = ["data", 0, "data_blob", "data", 0, "dataVersion"]

    # cve_metadata = ["data", 0, "data_blob", "data", 0, "cveMetadata"]
    # feed_cve_id = ["data", 0, "data_blob", "data", 0, "cveMetadata", "cveId"]
    # assigner_org_id = ["data", 0, "data_blob", "data", 0, "cveMetadata", "assignerOrgId"]
    # state = [ "data", 0, "data_blob", "data", 0, "cveMetadata", "state"]

    # containers = ["data", 0, "data_blob", "data", 0, "containers"]
    # cna = ["data", 0, "data_blob", "data", 0, "containers", "cna"]
    # provider_metadata = ["data", 0, "data_blob", "data", 0, "containers", "cna", "providerMetadata"]
    # org_id = ["data", 0, "data_blob", "data", 0, "containers", "cna", "providerMetadata", "orgId"]
    # descriptions = ["data", 0, "data_blob", "data", 0, "containers", "cna", "descriptions"]
    # lang = ["data", 0, "data_blob", "data", 0, "containers", "cna", "descriptions" , 0 , "lang"]
    # value = ["data", 0, "data_blob", "data", 0, "containers", "cna", "descriptions" , 0 , "value"]
    # affected = ["data", 0, "data_blob", "data", 0, "containers", "cna", "affected"]
    # references = ["data", 0, "data_blob", "data", 0, "containers", "cna", "references"]
    # url = ["data", 0, "data_blob", "data", 0, "containers", "cna", "references", 0, "url"]

    # required_keys = [source, data, operation, cve_id, data_hash, data_blob, data_type, data_version, cve_metadata, feed_cve_id, assigner_org_id, state, containers,
    #                  cna, provider_metadata, org_id, descriptions, lang, value, affected, references, url]

    # for key in required_keys:
    #     assert keys_exists(cve5_file, key), f"Key {key} does not exist"



def keys_exists(element, keys):
    '''
    Check if *keys (nested) exists in `element` (dict).
    '''
    if not isinstance(element, dict):
        raise AttributeError('keys_exists() expects dict as first argument.')
    if len(keys) == 0:
        raise AttributeError('keys_exists() expects at least two arguments, one given.')

    _element = element
    for key in keys:
        try:
            _element = _element[key]
        except KeyError:
            return False
    return True


