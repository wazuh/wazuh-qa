import json
import os
import shutil
from typing import final
import pytest
from subprocess import run
import jsonschema
from wazuh_testing.tools.file import read_yaml
from wazuh_testing.tools import file
from jsonschema import validate
from wazuh_testing.tools import configuration


test_data_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'data')
test_cases_path = os.path.join(test_data_path, 'test_cases')
feed_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), '..', 'data')


t1_test_cases_feeds_path = os.path.join(test_cases_path, 'cases_cve5_format.yaml')
t2_test_cases_feeds_path = os.path.join(test_cases_path, 'cases_validate_feed_from_vendor_format.yaml')


#Input feeds
test_input_nvd_feed_path = os.path.join(feed_path, 'input_feed', 'nvd', 'nvd_feed.json')
test_input_debian_feed_path = os.path.join(feed_path, 'input_feed', 'debian', 'debian_feed.json')
test_input_alas_json_feed_path = os.path.join(feed_path, 'input_feed', 'alas', 'alas_feed.json')
test_input_canonical_feed_path = os.path.join(feed_path, 'input_feed', 'canonical', 'canonical_feed.xml')
test_input_msu_feed_path = os.path.join(feed_path, 'input_feed', 'msu', 'msu_feed.json')
test_input_redhat_feed_path = os.path.join(feed_path, 'input_feed', 'redhat', 'redhat_feed.json')
test_input_arch_feed_path = os.path.join(feed_path, 'input_feed', 'arch', 'arch_feed.json')

# Output feed (mocked until migration tool is ready)
test_output_feed_path = os.path.join(feed_path, 'output_feed', 'cve5.json')
test_output_schema_path = os.path.join(feed_path, 'output_feed', 'cve_5.0_schema.json')

ref_imports_path = os.path.join(feed_path, 'output_feed', 'imports', 'cvss')
ref_tags = os.path.join(feed_path, 'output_feed', 'tags')

# Path to save tool output
output_path = "/tmp"

t2_metadata = [item['metadata'] for item in read_yaml(t2_test_cases_feeds_path)]
_, t1_configuration_metadata, t1_test_case_ids = configuration.get_test_cases_data(t1_test_cases_feeds_path)
_, t2_configuration_metadata, t2_test_case_ids = configuration.get_test_cases_data(t2_test_cases_feeds_path)


# Set offline custom feeds configuration
to_modify = ['CUSTOM_NVD_FEED_JSON_PATH', 'CUSTOM_DEBIAN_FEED_JSON_PATH', 'CUSTOM_ALAS_FEED_JSON_PATH',
             'CUSTOM_CANONICAL_FEED_JSON_PATH', 'CUSTOM_MSU_FEED_JSON_PATH', 'CUSTOM_REDHAT_FEED_JSON_PATH',
             'CUSTOM_ARCH_FEED_JSON_PATH']
new_values = [test_input_nvd_feed_path, test_input_debian_feed_path, test_input_alas_json_feed_path,
              test_input_canonical_feed_path, test_input_msu_feed_path, test_input_redhat_feed_path,
              test_input_arch_feed_path]


t1_configuration_metadata = configuration.update_configuration_template(t1_configuration_metadata, to_modify, new_values)

@pytest.fixture(scope='function')
def copy_references_json():
    """Copy in tmp folder files necessary to json schema """

    # Copy configuration
    shutil.copytree(ref_tags, '/tmp', dirs_exist_ok=True)
    shutil.copytree(ref_imports_path, '/tmp', dirs_exist_ok=True)

@pytest.mark.parametrize('metadata', t2_configuration_metadata, ids=t2_test_case_ids)
def test_format_vendor_feed(metadata, copy_references_json):

   # Download feed from vendor
    url = metadata['url']
    filename = metadata['filename']
    format = metadata['format']

    os.system(f"curl {url} -o {filename}")

    # Execute migration tool
    os.chdir("/home/belen/Repositories/wazuh-content/build/third_party_migration/")
    os.system(f"./content_migration -i {filename} -t {format} -o {output_path}")

    validate_output(test_output_feed_path, test_output_schema_path)


@pytest.mark.parametrize('metadata', t1_configuration_metadata, ids=t1_test_case_ids)
def test_format_cve5(metadata, copy_references_json):

    format = metadata['format']

    # Validate input file is a correct json
    assert file.validate_json_file(test_input_nvd_feed_path), "File is not JSON 'parseable'"

    # Execute migration tool
    os.chdir("/home/belen/Repositories/wazuh-content/build/third_party_migration/")
    os.system(f"./content_migration -i {test_input_nvd_feed_path} -t {format} -o {output_path}")

    validate_output(test_output_feed_path, test_output_schema_path)


def validate_output(output_feed, schema):

    # Validate output file is a correct json
    assert file.validate_json_file(output_feed), "File is not JSON 'parseable'"

    cve5_file= file.read_json_file(output_feed)

    schema_file= file.read_json_file(schema)

    # Validate required keys added by Wazuh
    source = ["source"]
    data = ["data"]
    operation = ["data", 0, "operation"]
    cve_id = ["data", 0, "cve_id"]
    data_hash = ["data", 0, "data_hash"]
    data_blob = ["data", 0, "data_blob"]

    required_keys = [source, data, operation, cve_id, data_hash, data_blob]

    for key in required_keys:
        assert keys_exists(cve5_file, key), f"Key {key} does not exist"

    # Validate output is a correct cve5
    final_cve5_file = cve5_file['data'][0]['data_blob']['data'][0]

    isValid = validate_cve_format(final_cve5_file, schema_file)

    if isValid:
        #print(expected_cve)
        print("Given JSON data is Valid")
    else:
       #print(expected_cve)
        print("Given JSON data is InValid")



def validate_cve_format(cve_file, schema_file):
    'Function to validate cve 5 schema'
    try:
        validate(instance=cve_file, schema=schema_file)
    except jsonschema.exceptions.ValidationError as e:
        print(e.message)
        return False
    return True


def keys_exists(element, keys):
    '''
    Check if *keys (nested) exists in `element` (dict).
    '''
    if not isinstance(element, dict):
        raise AttributeError('keys_exists() expects dict as first argument.')
    if len(keys) == 0:
        raise AttributeError('keys_exists() expects at least two arguments, one given.')

    _element = element
    for key in keys:
        try:
            _element = _element[key]
        except KeyError:
            return False
    return True


