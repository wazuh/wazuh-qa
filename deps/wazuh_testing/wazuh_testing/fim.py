# Copyright (C) 2015-2020, Wazuh Inc.
# Created by Wazuh, Inc. <info@wazuh.com>.
# This program is free software; you can redistribute it and/or modify it under the terms of GPLv2

import json
import os
import platform
import re
import shutil
import socket
import subprocess
import sys
import tempfile
import time
from collections import Counter
from copy import deepcopy
from datetime import datetime
from datetime import timedelta
from json import JSONDecodeError
from stat import ST_ATIME, ST_MTIME
from typing import Sequence, Union, Generator, Any

import pytest
from jsonschema import validate

from wazuh_testing import global_parameters, logger
from wazuh_testing.tools import LOG_FILE_PATH, WAZUH_PATH
from wazuh_testing.tools.time import TimeMachine

if sys.platform == 'win32':
    import win32con
    import win32api
    import winreg
elif sys.platform == 'linux2' or sys.platform == 'linux':
    from jq import jq

_data_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'data')

if sys.platform == 'win32':
    _REQUIRED_AUDIT = {"path", "process_id", "process_name", "user_id", "user_name"}

else:
    _REQUIRED_AUDIT = {'user_id', 'user_name', 'group_id', 'group_name', 'process_name', 'path', 'audit_uid',
                       'audit_name', 'effective_uid', 'effective_name', 'ppid', 'process_id'
                       }

FIFO = 'fifo'
SYMLINK = 'sym_link'
HARDLINK = 'hard_link'
SOCKET = 'socket'
REGULAR = 'regular'

CHECK_ALL = 'check_all'
CHECK_SUM = 'check_sum'
CHECK_SHA1SUM = 'check_sha1sum'
CHECK_MD5SUM = 'check_md5sum'
CHECK_SHA256SUM = 'check_sha256sum'
CHECK_SIZE = 'check_size'
CHECK_OWNER = 'check_owner'
CHECK_GROUP = 'check_group'
CHECK_PERM = 'check_perm'
CHECK_ATTRS = 'check_attrs'
CHECK_MTIME = 'check_mtime'
CHECK_INODE = 'check_inode'

REQUIRED_ATTRIBUTES = {
    CHECK_SHA1SUM: 'hash_sha1',
    CHECK_MD5SUM: 'hash_md5',
    CHECK_SHA256SUM: 'hash_sha256',
    CHECK_SIZE: 'size',
    CHECK_OWNER: ['uid', 'user_name'],
    CHECK_GROUP: ['gid', 'group_name'],
    CHECK_PERM: 'perm',
    CHECK_ATTRS: 'attributes',
    CHECK_MTIME: 'mtime',
    CHECK_INODE: 'inode',
    CHECK_ALL: {CHECK_SHA256SUM, CHECK_SHA1SUM, CHECK_MD5SUM, CHECK_SIZE, CHECK_OWNER,
                CHECK_GROUP, CHECK_PERM, CHECK_ATTRS, CHECK_MTIME, CHECK_INODE},
    CHECK_SUM: {CHECK_SHA1SUM, CHECK_SHA256SUM, CHECK_MD5SUM}
}

_last_log_line = 0


def validate_event(event, checks=None, mode=None):
    """
    Check if event is properly formatted according to some checks.

    Parameters
    ----------
    event : dict
        Represents an event generated by syscheckd.
    checks : set, optional
        Set of XML CHECK_* options. Default `{CHECK_ALL}`
    mode : str, optional
        Represents the FIM mode expected for the event to validate
    """

    def get_required_attributes(check_attributes, result=None):
        result = set() if result is None else result
        for check in check_attributes:
            mapped = REQUIRED_ATTRIBUTES[check]
            if isinstance(mapped, str):
                result |= {mapped}
            elif isinstance(mapped, list):
                result |= set(mapped)
            elif isinstance(mapped, set):
                result |= get_required_attributes(mapped, result=result)
        return result

    json_file = 'syscheck_event_windows.json' if sys.platform == "win32" else 'syscheck_event.json'
    with open(os.path.join(_data_path, json_file), 'r') as f:
        schema = json.load(f)
    validate(schema=schema, instance=event)

    # Check FIM mode
    mode = global_parameters.current_configuration['metadata']['fim_mode'] if mode is None else mode.replace('-', '')
    assert (event['data']['mode']).replace('-', '') == mode, f"The event's FIM mode was '{event['data']['mode']}' \
but was expected to be '{mode}'"

    # Check attributes
    if checks:
        attributes = event['data']['attributes'].keys() - {'type', 'checksum'}

        required_attributes = get_required_attributes(checks)
        required_attributes -= get_required_attributes({CHECK_GROUP}) if sys.platform == "win32" else {'attributes'}

        intersection = attributes ^ required_attributes
        intersection_debug = "Event attributes are: " + str(attributes)
        intersection_debug += "\nRequired Attributes are: " + str(required_attributes)
        intersection_debug += "\nIntersection is: " + str(intersection)
        assert (intersection == set()), f'Attributes and required_attributes are not the same. ' + intersection_debug

        # Check audit
        if event['data']['mode'] == 'whodata':
            assert ('audit' in event['data']), f'audit no detected in event'
            assert (event['data']['audit'].keys() ^ _REQUIRED_AUDIT == set()), \
                f'audit keys and required_audit are no the same'

        # Check add file event
        if event['data']['type'] == 'added':
            assert 'old_attributes' not in event['data'] and 'changed_attributes' not in event['data']
        # Check modify file event
        if event['data']['type'] == 'modified':
            assert 'old_attributes' in event['data'] and 'changed_attributes' in event['data']

            old_attributes = event['data']['old_attributes'].keys() - {'type', 'checksum'}
            old_intersection = old_attributes ^ required_attributes
            old_intersection_debug = "Event attributes are: " + str(old_attributes)
            old_intersection_debug += "\nRequired Attributes are: " + str(required_attributes)
            old_intersection_debug += "\nIntersection is: " + str(old_intersection)
            assert (old_intersection == set()), f'Old_attributes and required_attributes are not the same. ' + old_intersection_debug


def is_fim_scan_ended():
    message = 'File integrity monitoring scan ended.'
    line_number = 0
    with open(LOG_FILE_PATH, 'r') as f:
        for line in f:
            line_number += 1
            if line_number > _last_log_line:  # Ignore if has not reached from_line
                if message in line:
                    globals()['_last_log_line'] = line_number
                    return line_number
    return -1


def create_file(type_, path, name, **kwargs):
    """
    Create a file in a given path. The path will be created in case it does not exists.

    Parameters
    ----------
    type_ : str
        Defined constant that specifies the type. It can be: FIFO, SYSLINK, Socket or REGULAR.
    path : str
        Path where the file will be created.
    name : str
        File name.

    Other Parameters
    ----------------
    content : str
        Content of the created regular file.
    target : str
        Path where the link will be pointing to.
    """

    try:
        logger.info("Creating file " + str(os.path.join(path, name)) + " of " + str(type_) + " type")
        os.makedirs(path, exist_ok=True, mode=0o777)
        if type_ != REGULAR:
            try:
                kwargs.pop('content')
            except KeyError:
                pass
        if type_ in (SYMLINK, HARDLINK) and 'target' not in kwargs:
            raise ValueError(f"'target' param is mandatory for type {type_}")
        getattr(sys.modules[__name__], f'_create_{type_}')(path, name, **kwargs)
    except OSError:
        logger.info("File could not be created.")
        pytest.skip("OS does not allow creating this file.")


def create_registry(key, subkey, arch):
    """
    Create a registry given the key and the subkey. The registry is opened if it already exists

    Parameters
    ----------
    key : str
        The key of the registry (HKEY_* constants).
    subkey : str
        The subkey (name) of the registry.
    """
    sys.platform == 'win32' and winreg.CreateKey(key, subkey)


def _create_fifo(path, name):
    """
    Create a FIFO file.

    Parameters
    ----------
    path : str
        Path where the file will be created.
    name : str
        File name.
    """
    fifo_path = os.path.join(path, name)
    try:
        os.mkfifo(fifo_path)
    except OSError:
        raise


def _create_sym_link(path, name, target):
    """
    Create a symbolic link.

    Parameters
    ----------
    path : str
        Path where the symbolic link will be created.
    name : str
        File name.
    target : str
        Path where the symbolic link will be pointing to.
    """
    symlink_path = os.path.join(path, name)
    try:
        os.symlink(target, symlink_path)
    except OSError:
        raise


def _create_hard_link(path, name, target):
    """
    Create a hard link.

    Parameters
    ----------
    path : str
        Path where the hard link will be created.
    name : str
        File name.
    target : str
        Path where the hard link will be pointing to.
    """
    link_path = os.path.join(path, name)
    try:
        os.link(target, link_path)
    except OSError:
        raise


def _create_socket(path, name):
    """
    Create a Socket file.

    Parameters
    ----------
    path : str
        Path where the socket will be created.
    name : str
        File name.
    """
    socket_path = os.path.join(path, name)
    try:
        os.unlink(socket_path)
    except OSError:
        if os.path.exists(socket_path):
            raise
    sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
    sock.bind(socket_path)


def _create_regular(path, name, content=''):
    """
    Create a regular file.

    Parameters
    ----------
    path : str
        Path where the regular file will be created.
    name : str
        File name.
    content : str, optional
        Content of the created file. Default `''`
    """
    regular_path = os.path.join(path, name)
    mode = 'wb' if isinstance(content, bytes) else 'w'

    with open(regular_path, mode) as f:
        f.write(content)


def _create_regular_windows(path, name, content=''):
    regular_path = os.path.join(path, name)
    os.popen("echo " + content + " > " + regular_path + f" runas /user:{os.getlogin()}")


def delete_file(path, name):
    """
    Delete a regular file.

    Parameters
    ----------
    path : str
        Path to the file to be deleted.
    name : str
        Name of the file to be deleted
    """
    logger.info(f"Removing file {str(os.path.join(path, name))}")
    regular_path = os.path.join(path, name)
    if os.path.exists(regular_path):
        os.remove(regular_path)


def delete_registry(key, subkey, arch):
    """
    Delete a registry

    Parameters
    ----------
    key : str
        The key of the registry (HKEY_* constants).
    subkey : str
        The subkey (name) of the registry.
    """
    sys.platform == 'win32' and winreg.DeleteKeyEx(key, subkey, access=arch)


def modify_registry(key, subkey, value):
    """
    Modify the content of REG_SZ in a registry

    Parameters
    ----------
    key : str
        The key of the registry (HKEY_* constants)
    subkey : str
        The subkey (name) of the registry.
    value : str
        The value to be set.
    """
    logger.info("Modifying windows registry.")
    sys.platform == 'win32' and winreg.SetValue(key, subkey, winreg.REG_SZ, value)


def modify_file_content(path, name, new_content=None, is_binary=False):
    """
    Modify the content of a file.

    Parameters
    ----------
    path : str, bytes
        Path to the file to be modified.
    name : str, bytes
        Name of the file to be modified.
    new_content : str, optional
        New content to append to the file. Previous content will remain. Default `None`
    is_binary : boolean, optional
        True if the file's content is in binary format. False otherwise. Default `False`
    """
    path_to_file = os.path.join(path, name)
    logger.info("- Changing content of " + str(path_to_file))
    content = "1234567890qwertyu" if new_content is None else new_content
    with open(path_to_file, 'ab' if is_binary else 'a') as f:
        f.write(content.encode() if is_binary else content)


def modify_file_mtime(path, name):
    """
    Change the modification time of a file.

    Parameters
    ----------
    path : str, bytes
        Path to the file to be modified.
    name : str, bytes
        Name of the file to be modified.
    """
    path_to_file = os.path.join(path, name)
    logger.info("- Changing mtime of " + str(path_to_file))
    stat = os.stat(path_to_file)
    access_time = stat[ST_ATIME]
    modification_time = stat[ST_MTIME]
    modification_time = modification_time + 1000
    os.utime(path_to_file, (access_time, modification_time))


def modify_file_owner(path, name):
    """
    Change the owner of a file. The new owner will be '1'.

    On Windows, uid will always be 0.

    Parameters
    ----------
    path : str, bytes
        Path to the file to be modified.
    name : str, bytes
        Name of the file to be modified.
    """
    def modify_file_owner_windows():
        cmd = f"takeown /S 127.0.0.1 /U {os.getlogin()} /F " + path_to_file
        subprocess.call(cmd)

    def modify_file_owner_unix():
        os.chown(path_to_file, 1, -1)

    path_to_file = os.path.join(path, name)
    logger.info("- Changing owner of " + str(path_to_file))

    if sys.platform == 'win32':
        modify_file_owner_windows()
    else:
        modify_file_owner_unix()


def modify_file_group(path, name):
    """
    Change the group of a file. The new group will be '1'.

    Available for UNIX. On Windows, gid will always be 0 and the group name will be blank.

    Parameters
    ----------
    path : str, bytes
        Path to the file to be modified.
    name : str, bytes
        Name of the file to be modified.
    """
    if sys.platform == 'win32':
        return

    path_to_file = os.path.join(path, name)
    logger.info("- Changing group of " + str(path_to_file))
    os.chown(path_to_file, -1, 1)


def modify_file_permission(path, name):
    """
    Change the permision of a file.

    On UNIX the new permissions will be '666'.
    On Windows, a list of denied and allowed permissions will be given for each user or group since version 3.8.0.
    Only works on NTFS partitions on Windows systems.

    Parameters
    ----------
    path : str, bytes
        Path to the file to be modified.
    name : str, bytes
        Name of the file to be modified.
    """
    def modify_file_permission_windows():
        import win32security
        import ntsecuritycon

        user, domain, account_type = win32security.LookupAccountName(None, f"{platform.node()}\\{os.getlogin()}")
        sd = win32security.GetFileSecurity(path_to_file, win32security.DACL_SECURITY_INFORMATION)
        dacl = sd.GetSecurityDescriptorDacl()
        dacl.AddAccessAllowedAce(win32security.ACL_REVISION, ntsecuritycon.FILE_ALL_ACCESS, user)
        sd.SetSecurityDescriptorDacl(1, dacl, 0)
        win32security.SetFileSecurity(path_to_file, win32security.DACL_SECURITY_INFORMATION, sd)

    def modify_file_permission_unix():
        os.chmod(path_to_file, 0o666)

    path_to_file = os.path.join(path, name)

    logger.info("- Changing permission of " + str(path_to_file))

    if sys.platform == 'win32':
        modify_file_permission_windows()
    else:
        modify_file_permission_unix()


def modify_file_inode(path, name):
    """
    Change the inode of a file.

    Parameters
    ----------
    path : str, bytes
        Path to the file to be modified.
    name : str, bytes
        Name of the file to be modified.
    """
    if sys.platform == 'win32':
        return

    logger.info("- Changing inode of " + str(os.path.join(path, name)))
    inode_file = 'inodetmp'
    path_to_file = os.path.join(path, name)

    shutil.copy2(path_to_file, os.path.join(tempfile.gettempdir(), inode_file))
    os.replace(os.path.join(tempfile.gettempdir(), inode_file), path_to_file)


def modify_file_win_attributes(path, name):
    if sys.platform != 'win32':
        return

    logger.info("- Changing win attributes of " + str(os.path.join(path, name)))
    path_to_file = os.path.join(path, name)
    win32api.SetFileAttributes(path_to_file, win32con.FILE_ATTRIBUTE_HIDDEN)


def modify_file(path, name, new_content=None, is_binary=False):
    """
    Modify a Regular file.

    Parameters
    ----------
    path : str, bytes
        Path where the file will be created.
    name : str, bytes
        File name.
    new_content : str, optional
        New content to add to the file. Default `None`
    is_binary : boolean, optional
        True if the file is binary. False otherwise. Default `False`
    """
    logger.info("Modifying file " + str(os.path.join(path, name)))
    modify_file_inode(path, name)
    modify_file_content(path, name, new_content, is_binary)
    modify_file_mtime(path, name)
    modify_file_owner(path, name)
    modify_file_group(path, name)
    modify_file_permission(path, name)
    modify_file_win_attributes(path, name)


def change_internal_options(param, value, opt_path=None):
    """
    Change the value of a given parameter in local_internal_options.

    Parameters
    ----------
    param : str
        Parameter to change.
    value : str or int
        New value.
    opt_path : str, optional
        local_internal_options.conf path. Default `None`
    """
    if opt_path is None:
        local_conf_path = os.path.join(WAZUH_PATH, 'local_internal_options.conf') if sys.platform == 'win32' else \
            os.path.join(WAZUH_PATH, 'etc', 'local_internal_options.conf')
    else:
        local_conf_path = opt_path

    add_pattern = True
    with open(local_conf_path, "r") as sources:
        lines = sources.readlines()

    with open(local_conf_path, "w") as sources:
        for line in lines:
            sources.write(
                re.sub(f'{param}=[0-9]*', f'{param}={value}', line))
            if param in line:
                add_pattern = False

    if add_pattern:
        with open(local_conf_path, "a") as sources:
            sources.write(f'\n\n{param}={value}')


def change_conf_param(param, value):
    """
    Change the value of a given parameter in ossec.conf.

    Parameters
    ----------
    param : str
        Parameter to change.
    value : str or int
        New value.
    """
    conf_path = os.path.join(WAZUH_PATH, 'ossec.conf') if sys.platform == 'win32' else \
        os.path.join(WAZUH_PATH, 'etc', 'ossec.conf')

    with open(conf_path, "r") as sources:
        lines = sources.readlines()

    with open(conf_path, "w") as sources:
        for line in lines:
            sources.write(
                re.sub(f'<{param}>.*</{param}>', f'<{param}>{value}</{param}>', line))


def callback_detect_end_scan(line):
    if 'File integrity monitoring scan ended.' in line:
        return line
    return None


def callback_detect_event(line):
    msg = r'.*Sending FIM event: (.+)$'
    match = re.match(msg, line)

    try:
        if json.loads(match.group(1))['type'] == 'event':
            return json.loads(match.group(1))
    except (AttributeError, JSONDecodeError, KeyError):
        pass

    return None


def callback_detect_integrity_event(line):
    match = re.match(r'.*Sending integrity control message: (.+)$', line)
    if match:
        return json.loads(match.group(1))
    return None


def callback_detect_integrity_state(line):
    event = callback_detect_integrity_event(line)
    if event:
        if event['type'] == 'state':
            return event
    return None


def callback_detect_synchronization(line):
    if 'Performing synchronization check' in line:
        return line
    return None


def callback_detect_anything(line):
    match = re.match(r'.*', line)
    if match:
        return line
    return None


def callback_ignore(line):
    match = re.match(r".*Ignoring '.*?' '(.*?)' due to( sregex)? '.*?'", line)
    if match:
        return match.group(1)
    return None


def callback_restricted(line):
    match = re.match(r".*Ignoring file '(.*?)' due to restriction '.*?'", line)
    if match:
        return match.group(1)
    return None


def callback_audit_health_check(line):
    if 'Whodata health-check: Success.' in line:
        return True
    return None


def callback_audit_cannot_start(line):
    match = re.match(r'.*Who-data engine could not start. Switching who-data to real-time.', line)
    if match:
        return True
    return None


def callback_audit_added_rule(line):
    match = re.match(r'.*Added audit rule for monitoring directory: \'(.+)\'', line)
    if match:
        return match.group(1)
    return None


def callback_audit_rules_manipulation(line):
    if 'Detected Audit rules manipulation' in line:
        return True
    return None


def callback_audit_removed_rule(line):
    match = re.match(r'.* Audit rule removed.', line)
    if match:
        return True
    return None


def callback_audit_deleting_rule(line):
    match = re.match(r'.*Deleting Audit rules\.', line)
    if match:
        return True
    return None


def callback_audit_connection(line):
    if '(6030): Audit: connected' in line:
        return True
    return None


def callback_audit_connection_close(line):
    match = re.match(r'.*Audit: connection closed.', line)
    if match:
        return True
    return None


def callback_audit_loaded_rule(line):
    match = re.match(r'.*Audit rule loaded: -w (.+) -p', line)
    if match:
        return match.group(1)
    return None


def callback_audit_event_too_long(line):
    if 'Caching Audit message: event too long' in line:
        return True
    return None


def callback_audit_reloading_rules(line):
    match = re.match(r'.*Reloading Audit rules', line)
    if match:
        return True


def callback_audit_reloaded_rule(line):
    match = re.match(r'.*Reloaded audit rule for monitoring directory: \'(.+)\'', line)
    if match:
        return match.group(1)
    return None


def callback_audit_key(line):
    if 'Match audit_key' in line and 'key="wazuh_hc"' not in line and 'key="wazuh_fim"' not in line:
        return line
    return None


def callback_audit_unable_dir(line):
    match = re.match(r'.*Unable to add audit rule for \'(.+)\'', line)
    if match:
        return match.group(1)
    return None


def callback_realtime_added_directory(line):
    match = re.match(r'.*Directory added for real time monitoring: \'(.+)\'', line)
    if match:
        return match.group(1)
    return None


def callback_configuration_error(line):
    match = re.match(r'.*CRITICAL: \(\d+\): Configuration error at', line)
    if match:
        return True
    return None


def callback_symlink_scan_ended(line):
    if 'Links check finalized.' in line:
        return True
    else:
        return None


def callback_syscheck_message(line):
    if callback_detect_integrity_event(line) or callback_detect_event(line):
        match = re.match(r"(\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}).*({.*?})$", line)
        if match:
            return datetime.strptime(match.group(1), '%Y/%m/%d %H:%M:%S'), json.dumps(match.group(2))
        return None


def callback_empty_directories(line):
    match = re.match(r'.*DEBUG: \(6338\): Empty directories tag found in the configuration.', line)

    if match:
        return True
    else:
        return None


def check_time_travel(time_travel):
    """
    Change date and time of the system.

    Parameters
    ----------
    time_travel : boolean
        True if we need to update time. False otherwise.
    """
    if time_travel:
        before = str(datetime.now())
        TimeMachine.travel_to_future(timedelta(hours=13))
        logger.info(f"Changing the system clock from {before} to {str(datetime.now())}")


def callback_configuration_warning(line):
    match = re.match(r'.*WARNING: \(\d+\): Invalid value for element', line)
    if match:
        return True
    return None


def callback_entries_path_count(line):
    match = re.match(r'.*Fim inode entries: (\d+), path count: (\d+)', line)

    if match:
        return match.group(1), match.group(2)


class EventChecker:
    """Utility to allow fetch events and validate them."""

    def __init__(self, log_monitor, folder, file_list=['testfile0'], options=None, custom_validator=None, encoding=None):
        self.log_monitor = log_monitor
        self.folder = folder
        self.file_list = file_list
        self.custom_validator = custom_validator
        self.options = options
        self.encoding = encoding
        self.events = None

    def fetch_and_check(self, event_type, min_timeout=1, triggers_event=True, extra_timeout=0):
        """
        Call both 'fetch_events' and 'check_events'.

        Parameters
        ----------
        event_type : {'added', 'modified', 'deleted'}
            Expected type of the raised event.
        min_timeout : int, optional
            Seconds to wait until an event is raised when trying to fetch. Default `1`
        triggers_event : boolean, optional
            True if the event should be raised. False otherwise. Default `True`
        extra_timeout : int, optional
            Additional time to wait after the min_timeout
        """
        num_files = len(self.file_list)
        error_msg = "TimeoutError was raised because "
        error_msg += str(num_files) if num_files > 1 else "a single"
        error_msg += " '" + str(event_type) + "' "
        error_msg += "events were " if num_files > 1 else "event was "
        error_msg += "expected for " + str(self._get_file_list())
        error_msg += " but were not detected." if len(self.file_list) > 1 else " but was not detected."

        self.events = self.fetch_events(min_timeout, triggers_event, extra_timeout, error_message=error_msg)
        self.check_events(event_type)

    def fetch_events(self, min_timeout=1, triggers_event=True, extra_timeout=0, error_message=''):
        """
        Try to fetch events on a given log monitor. Will return a list with the events detected.

        Parameters
        ----------
        min_timeout : int, optional
            Seconds to wait until an event is raised when trying to fetch. Default `1`
        triggers_event : boolean, optional
            True if the event should be raised. False otherwise. Default `True`
        extra_timeout : int, optional
            Additional time to wait after the min_timeout
        error_message : str
            Message to explain a possible timeout error
        """
        def clean_results(event_list):
            """Iterate the event_list provided and check if the 'modified' events contained should be merged to fix
            whodata's bug that raise more than one modification event when a file is modified. If some 'modified' event
            shares 'path' and 'timestamp' we assume that belongs to the same modification.
            """
            if not isinstance(event_list, list):
                return event_list
            result_list = list()
            previous = None
            while(len(event_list) > 0):
                current = event_list.pop(0)
                if current['data']['type'] == "modified":
                    if not previous:
                        previous = current
                    elif (previous['data']['path'] == current['data']['path'] and
                          current['data']['timestamp'] in [previous['data']['timestamp'],
                                                           previous['data']['timestamp'] + 1]):
                        previous['data']['changed_attributes'] = list(set(previous['data']['changed_attributes']
                                                                          + current['data']['changed_attributes']))
                        previous['data']['attributes'] = current['data']['attributes']
                    else:
                        result_list.append(previous)
                        previous = current
                else:
                    result_list.append(current)
            if previous:
                result_list.append(previous)
            return result_list

        try:
            result = self.log_monitor.start(timeout=max(len(self.file_list) * 0.01, min_timeout),
                                            callback=callback_detect_event,
                                            accum_results=len(self.file_list),
                                            timeout_extra=extra_timeout,
                                            encoding=self.encoding,
                                            error_message=error_message).result()
            assert triggers_event, f'No events should be detected.'
            if extra_timeout > 0:
                result = clean_results(result)
            return result if isinstance(result, list) else [result]
        except TimeoutError:
            if triggers_event:
                raise
            logger.info("TimeoutError was expected and correctly caught.")

    def check_events(self, event_type):
        """Check and validate all events in the 'events' list.

        Parameters
        ----------
        event_type : {'added', 'modified', 'deleted'}
            Expected type of the raised event.
        """
        def validate_checkers_per_event(events, options):
            """Check if each event is properly formatted according to some checks.

            Parameters
            ----------
            events : list
                Event list to be checked.
            options : set
                Set of XML CHECK_* options. Default `{CHECK_ALL}`
            """
            for ev in events:
                validate_event(ev, options)

        def check_events_type(events, ev_type, file_list=['testfile0']):
            event_types = Counter(filter_events(events, ".[].data.type"))
            assert (event_types[ev_type] == len(file_list)), f'Non expected number of events. {event_types[ev_type]} != {len(file_list)}'

        def check_files_in_event(events, folder, file_list=['testfile0']):
            file_paths = filter_events(events, ".[].data.path")
            for file_name in file_list:
                expected_file_path = os.path.join(folder, file_name)
                expected_file_path = expected_file_path[:1].lower() + expected_file_path[1:]
                if self.encoding is not None:
                    for index, item in enumerate(file_paths):
                        file_paths[index] = item.encode(encoding=self.encoding)
                if sys.platform == 'darwin' and self.encoding and self.encoding != 'utf-8':
                    logger.info(f'Not asserting {expected_file_path} in event.data.path. '
                                 f'Reason: using non-utf-8 encoding in darwin.')
                else:
                    assert (expected_file_path in file_paths), f'{expected_file_path} does not exist in {file_paths}'

        def filter_events(events, mask):
            """Returns a list of elements matching a specified mask in the events list using jq module."""
            if sys.platform in ("win32", 'sunos5', 'darwin'):
                stdout = subprocess.check_output(["jq", "-r", mask], input=json.dumps(events).encode())
                return stdout.decode("utf8").strip().split(os.linesep)
            else:
                return jq(mask).transform(events, multiple_output=True)

        if self.events is not None:
            validate_checkers_per_event(self.events, self.options)
            check_events_type(self.events, event_type, self.file_list)
            check_files_in_event(self.events, self.folder, self.file_list)

            if self.custom_validator is not None:
                self.custom_validator.validate_after_cud(self.events)
                if event_type == "added":
                    self.custom_validator.validate_after_create(self.events)
                elif event_type == "modified":
                    self.custom_validator.validate_after_update(self.events)
                elif event_type == "deleted":
                    self.custom_validator.validate_after_delete(self.events)
    def _get_file_list(self):
        result_list = []
        for file_name in self.file_list:
            expected_file_path = os.path.join(self.folder, file_name)
            expected_file_path = expected_file_path[:1].lower() + expected_file_path[1:]
            result_list.append(expected_file_path)
        return result_list


class CustomValidator:
    """Enable using user-defined validators over the events when validating them with EventChecker"""
    def __init__(self, validators_after_create=None, validators_after_update=None,
                 validators_after_delete=None, validators_after_cud=None):
        self.validators_create = validators_after_create
        self.validators_update = validators_after_update
        self.validators_delete = validators_after_delete
        self.validators_cud = validators_after_cud

    def validate_after_create(self, events):
        """
        Custom validators to be applied by default when the event_type is 'added'.

        Parameters
        ----------
        events : list
            List of events to be validated.
        """
        if self.validators_create is not None:
            for event in events:
                for validator in self.validators_create:
                    validator(event)

    def validate_after_update(self, events):
        """
        Custom validators to be applied by default when the event_type is 'modified'.

        Parameters
        ----------
        events : list
            List of events to be validated.
        """
        if self.validators_update is not None:
            for event in events:
                for validator in self.validators_update:
                    validator(event)

    def validate_after_delete(self, events):
        """
        Custom validators to be applied by default when the event_type is 'deleted'.

        Parameters
        ----------
        events : list
            List of events to be validated.
        """
        if self.validators_delete is not None:
            for event in events:
                for validator in self.validators_delete:
                    validator(event)

    def validate_after_cud(self, events):
        """
        Custom validators to be applied always by default.

        Parameters
        ----------
        events : list
            List of events to be validated.
        """
        if self.validators_cud is not None:
            for event in events:
                for validator in self.validators_cud:
                    validator(event)


def regular_file_cud(folder, log_monitor, file_list=['testfile0'], time_travel=False, min_timeout=1, options=None,
                     triggers_event=True, encoding=None, validators_after_create=None, validators_after_update=None,
                     validators_after_delete=None, validators_after_cud=None):
    """
    Check if creation, update and delete events are detected by syscheck.

    This function provides multiple tools to validate events with custom validators.

    Parameters
    ----------
    folder : str
        Path where the files will be created.
    log_monitor : FileMonitor
        File event monitor.
    file_list : list(str) or dict, optional
        If it is a list, it will be transformed to a dict with empty strings in each value. Default `['testfile0']`
    time_travel : boolean, optional
        Boolean to determine if there will be time travels or not. Default `False`
    min_timeout : int, optional
        Minimum timeout. Default `1`
    options : set, optional
        Set with all the checkers. Default `None`
    triggers_event : boolean, optional
        Boolean to determine if the event should be raised or not. Default `True`
    encoding : str, optional
        String to determine the encoding of the file name. Default `None`
    validators_after_create : list, optional
        List of functions that validates an event triggered when a new file is created. Each function must accept
        a param to receive the event to be validated. Default `None`
    validators_after_update : list, optional
        List of functions that validates an event triggered when a new file is modified. Each function must accept
        a param to receive the event to be validated. Default `None`
    validators_after_delete : list, optional
        List of functions that validates an event triggered when a new file is deleted. Each function must accept
        a param to receive the event to be validated. Default `None`
    validators_after_cud : list, optional
        List of functions that validates an event triggered when a new file is created, modified or deleted. Each
        function must accept a param to receive the event to be validated. Default `None`
    """
    # Transform file list
    if not isinstance(file_list, list) and not isinstance(file_list, dict):
        raise ValueError('Value error. It can only be list or dict')
    elif isinstance(file_list, list):
        file_list = {i: '' for i in file_list}

    custom_validator = CustomValidator(validators_after_create, validators_after_update,
                                       validators_after_delete, validators_after_cud)
    event_checker = EventChecker(log_monitor=log_monitor, folder=folder, file_list=file_list, options=options,
                                 custom_validator=custom_validator, encoding=encoding)

    # Create text files
    for name, content in file_list.items():
        create_file(REGULAR, folder, name, content=content)

    check_time_travel(time_travel)
    event_checker.fetch_and_check('added', min_timeout=min_timeout, triggers_event=triggers_event)
    if triggers_event:
        logger.info("'added' {} detected as expected.\n".format("events" if len(file_list) > 1 else "event"))

    # Modify previous text files
    for name, content in file_list.items():
        modify_file(folder, name, is_binary=isinstance(content, bytes))

    check_time_travel(time_travel)
    event_checker.fetch_and_check('modified', min_timeout=min_timeout, triggers_event=triggers_event, extra_timeout=2)
    if triggers_event:
        logger.info("'modified' {} detected as expected.\n".format("events" if len(file_list) > 1 else "event"))

    # Delete previous text files
    for name in file_list:
        delete_file(folder, name)

    check_time_travel(time_travel)
    event_checker.fetch_and_check('deleted', min_timeout=min_timeout, triggers_event=triggers_event)
    if triggers_event:
        logger.info("'deleted' {} detected as expected.\n".format("events" if len(file_list) > 1 else "event"))


def detect_initial_scan(file_monitor):
    """
    Detect initial scan when restarting Wazuh.

    Parameters
    ----------
    file_monitor : FileMonitor
        File log monitor to detect events
    """
    file_monitor.start(timeout=60, callback=callback_detect_end_scan,
                       error_message='Did not receive expected "File integrity monitoring scan ended" event')


def generate_params(extra_params: dict = None, apply_to_all: Union[Sequence[Any], Generator[dict, None, None]] = None,
                    modes: list = None):
    """
    Expand params and metadata with optional FIM modes.

    extra_params = {'WILDCARD': {'attribute': ['list', 'of', 'values']}} - Max. 3 elements in the list of values
                        or
                   {'WILDCARD': {'attribute': 'value'}} - It will have the same value for scheduled, realtime and whodata
                        or
                   {'WILDCARD': 'value'} - Valid when param is not an attribute. (ex: 'MODULE_NAME': __name__)
                        or
                   {'WILDCARD': ['list', 'of', 'values']} - Same as above with multiple values. The length of the list
                                                            must be the same as the length of the mode list.

    apply_to_all = Same structure as above. The difference is, these params will be applied for every existing
                    configuration. They are applied after the `extra_params`.

    Examples
    --------
    >>> generate_params(extra_params={'REPORT_CHANGES': {'report_changes': ['yes', 'no']}, 'MODULE_NAME': 'name'},
    ...                 modes=['realtime', 'whodata'])
    ([{'FIM_MODE': {'realtime': 'yes'}, 'REPORT_CHANGES': {'report_changes': 'yes'}, 'MODULE_NAME': 'name'},
      {'FIM_MODE': {'whodata': 'yes'}, 'REPORT_CHANGES': {'report_changes': 'no'}, 'MODULE_NAME': 'name'}],
     [{'fim_mode': 'realtime', 'report_changes': 'yes', 'module_name': 'name'},
      {'fim_mode': 'whodata', 'report_changes': 'no', 'module_name': 'name'}])

    >>> generate_params(extra_params={'MODULE_NAME': 'name'}, apply_to_all={'FREQUENCY': {'frequency': [1, 2]}},
    ...                 modes=['scheduled', 'realtime'])
    ([{'FIM_MODE': '', 'MODULE_NAME': 'name', 'FREQUENCY': {'frequency': 1}},
      {'FIM_MODE': {'realtime': 'yes'}, 'MODULE_NAME': 'name', 'FREQUENCY': {'frequency': 1}},
      {'FIM_MODE': '', 'MODULE_NAME': 'name', 'FREQUENCY': {'frequency': 2}},
      {'FIM_MODE': {'realtime': 'yes'}, 'MODULE_NAME': 'name', 'FREQUENCY': {'frequency': 2}}],
     [{'fim_mode': 'scheduled', 'module_name': 'name', 'frequency': {'frequency': 1}},
      {'fim_mode': 'realtime', 'module_name': 'name', 'frequency': {'frequency': 1}},
      {'fim_mode': 'scheduled', 'module_name': 'name', 'frequency': {'frequency': 2}},
      {'fim_mode': 'realtime', 'module_name': 'name', 'frequency': {'frequency': 2}}])

    >>> generate_params(extra_params={'LIST_OF_VALUES': {'list': [[1,2,3]]}, 'MODULE_NAME': 'name'},
    ...                 modes=['scheduled'])
    ([{'FIM_MODE': '', 'LIST_OF_VALUES': {'list': [1, 2, 3]}, 'MODULE_NAME': 'name'}],
     [{'fim_mode': 'scheduled', 'list_of_values': [1, 2, 3], 'module_name': 'name'}])

    Parameters
    ----------
    extra_params : dict, optional
        Dictionary with all the extra parameters to add for every mode. Default `None`
    apply_to_all : iterable object or generator object
        Dictionary with all the extra parameters to add to every configuration. Default `None`
    modes : list, optional
        FIM modes to be applied. Default `None` (scheduled, realtime and whodata)

    Returns
    -------
    tuple (list, list)
        Tuple with the list of parameters and the list of metadata.
    """
    def transform_param(mutable_object: dict):
        """Transform `mutable_object` into a valid data structure."""
        for k, v in mutable_object.items():
            if isinstance(v, dict):
                for v_key, v_value in v.items():
                    mutable_object[k][v_key] = v_value if isinstance(v_value, list) else [v_value]*len(modes)
            elif not isinstance(v, list):
                mutable_object[k] = [v]*len(modes)

    fim_param = []
    fim_metadata = []

    # Get FIM params and metadata
    modes = modes if modes else ['scheduled', 'realtime', 'whodata']
    for mode in modes:
        param, metadata = get_fim_mode_param(mode)
        if param:
            fim_param.append(param)
            fim_metadata.append(metadata)

    # If we have extra_params to add, assert they have the exact number of elements as modes
    # Also, if there aren't extra_params, let `add` to False to at least put `FIM_MODES`
    add = False
    if extra_params:
        transform_param(extra_params)
        for _, value in extra_params.items():
            if isinstance(value, dict):
                assert len(next(iter(value.values()))) == len(modes), 'Length not equal between extra_params values ' \
                                                                      'and modes'
            else:
                assert len(value) == len(modes), 'Length not equal between extra_params values and modes'
        add = True

    params = []
    metadata = []

    # Iterate over fim_mode params and metadata and add one configuration for every existing fim_mode
    for i, (fim_mode_param, fim_mode_meta) in enumerate(zip(fim_param, fim_metadata)):
        p_aux: dict = deepcopy(fim_mode_param)
        m_aux: dict = deepcopy(fim_mode_meta)
        if add:
            for key, value in extra_params.items():
                p_aux[key] = {k: v[i] for k, v in value.items()} if isinstance(value, dict) else \
                    value[i] if isinstance(value, list) else value
                m_aux[key.lower()] = next(iter(value.values()))[i] if isinstance(value, dict) else \
                    value[i] if isinstance(value, list) else value
        params.append(p_aux)
        metadata.append(m_aux)

    # Append new parameters and metadata for every existing configuration
    if apply_to_all:
        aux_params = deepcopy(params)
        aux_metadata = deepcopy(metadata)
        params.clear()
        metadata.clear()
        for element in apply_to_all:
            for p_dict, m_dict in zip(aux_params, aux_metadata):
                params.append({**p_dict, **element})
                metadata.append({**m_dict, **{wildcard.lower(): value for wildcard, value in element.items()}})

    return params, metadata


def get_fim_mode_param(mode, key='FIM_MODE'):
    """Get the parameters for the FIM mode.

    This is useful to generate the directories tag with several fim modes. It also
    takes into account the current platform so realtime and whodata does not apply
    to darwin.

    Parameters
    ----------
    mode : string
        Must be one of the following 'scheduled', 'realtime' or 'whodata'
    key : string, optional
        Name of the placeholder expected in the target configuration. Default 'FIM_MODE'

    Returns
    -------
    tuple (dict, dict)
        Params: The key is `key` and the value is the string to be replaced in the target configuration.
        Metadata: The key is `key` in lowercase and the value is always `mode`.
    """
    metadata = {key.lower(): mode}
    if mode == 'scheduled':
        return {key: ''}, metadata
    elif mode == 'realtime' and sys.platform != 'darwin':
        return {key: {'realtime': 'yes'}}, metadata
    elif mode == 'whodata' and sys.platform != 'darwin':
        return {key: {'whodata': 'yes'}}, metadata
    else:
        return None, None
